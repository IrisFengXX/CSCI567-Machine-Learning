{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-1-445fd80c0c3b>, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-445fd80c0c3b>\"\u001b[0;36m, line \u001b[0;32m24\u001b[0m\n\u001b[0;31m    Xmtx=np.asmatrix(X)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Do not change the input and output format.\n",
    "If our script cannot run your code or the format is improper, your code will not be graded.\n",
    "\n",
    "The only functions you need to implement in this template is linear_regression_noreg, regularized_linear_regression,\n",
    "tune_lambda, and test_error.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "###### Q4.1 ######\n",
    "def linear_regression_noreg(X, y):\n",
    "  \"\"\"\n",
    "  Compute the weight parameter given X and y.\n",
    "  Inputs:\n",
    "  - X: A numpy array of shape (num_samples, D) containing feature.\n",
    "  - y: A numpy array of shape (num_samples, ) containing label\n",
    "  Returns:\n",
    "  - w: a numpy array of shape (D, )\n",
    "  \"\"\"\n",
    "  #####################################################\n",
    "  #\t\t\t\t YOUR CODE HERE\t\t\t\t\t                    #\n",
    "    Xmtx=np.asmatrix(X)\n",
    "    ymtx=np.asmatrix(y)\n",
    "    XmtxT=Xmtx.T\n",
    "    ymtxT=ymtx.T\n",
    "    w=numpy.asmatrix(np.linalg.pinv(np.asarray((XmtxT*Xmtx))))*XmtxT*ymtxT\n",
    "  #####################################################\t\t \n",
    "  return w\n",
    "\n",
    "###### Q4.2 ######\n",
    "def regularized_linear_regression(X, y, lambd):\n",
    "  \"\"\"\n",
    "    Compute the weight parameter given X, y and lambda.\n",
    "    Inputs:\n",
    "    - X: A numpy array of shape (num_samples, D) containing feature.\n",
    "    - y: A numpy array of shape (num_samples, ) containing label\n",
    "    - lambd: a float number containing regularization strength\n",
    "    Returns:\n",
    "    - w: a numpy array of shape (D, )\n",
    "    \"\"\"\n",
    "  #####################################################\n",
    "  #\t\t\t\t YOUR CODE HERE\t\t\t\t\t    #\n",
    "    Xmtx=np.asmatrix(X)\n",
    "    ymtx=np.asmatrix(y)\n",
    "    XmtxT=Xmtx.T\n",
    "    ymtxT=ymtx.T\n",
    "    I=np.identity(len(y))\n",
    "    w=numpy.asmatrix(np.linalg.pinv(numpy.asarray((XmtxT*Xmtx)))+lambd*I)*XmtxT*ymtxT\n",
    "  #####################################################\t\t \n",
    "  return w\n",
    "\n",
    "###### Q4.3 ###### \n",
    "def tune_lambda(Xtrain, ytrain, Xval, yval, lambds):\n",
    "  \"\"\"\n",
    "    Find the best lambda value.\n",
    "    Inputs:\n",
    "    - Xtrain: A numpy array of shape (num_training_samples, D) containing training feature.\n",
    "    - ytrain: A numpy array of shape (num_training_samples, ) containing training label\n",
    "    - Xval: A numpy array of shape (num_val_samples, D) containing validation feature.\n",
    "    - yval: A numpy array of shape (num_val_samples, ) containing validation label\n",
    "    - lambds: a list of lambdas\n",
    "    Returns:\n",
    "    - bestlambda: the best lambda you find in lambds\n",
    "    \"\"\"\n",
    "  #####################################################\n",
    "  #\t\t\t\t YOUR CODE HERE\t\t\t\t\t                    #\n",
    "    valerr=[]\n",
    "    Xmtx=np.asmatrix(Xtrain)\n",
    "    ymtx=np.asmatrix(ytrain)\n",
    "    XmtxT=Xmtx.T\n",
    "    ymtxT=ymtx.T\n",
    "    I=np.identity(len(y))\n",
    "    for lambd in lambds:\n",
    "        w_lambd=numpy.asmatrix(np.linalg.pinv(numpy.asarray((XmtxT*Xmtx)))+lambd*I)*XmtxT*ymtxT\n",
    "        y_pred=Xval*w_lambd.T\n",
    "        valerr.append(sum(y_pred-yval))\n",
    "        \n",
    "  #####################################################\t\t \n",
    "  return bestlambda\n",
    "\n",
    "###### Q4.4 ######\n",
    "def test_error(w, X, y):\n",
    "  \"\"\"\n",
    "    Compute the mean squre error on test set given X, y, and model parameter w.\n",
    "    Inputs:\n",
    "    - X: A numpy array of shape (num_samples, D) containing test feature.\n",
    "    - y: A numpy array of shape (num_samples, ) containing test label\n",
    "    - w: a numpy array of shape (D, )\n",
    "    Returns:\n",
    "    - err: the mean square error\n",
    "    \"\"\"\n",
    "  return err\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "NO MODIFICATIONS below this line.\n",
    "You should only write your code in the above functions.\n",
    "\"\"\"\n",
    "\n",
    "def data_processing():\n",
    "  white = pd.read_csv('winequality-white.csv', low_memory=False, sep=';').values\n",
    "\n",
    "  [N, d] = white.shape\n",
    "\n",
    "  np.random.seed(3)\n",
    "  # prepare data\n",
    "  ridx = np.random.permutation(N)\n",
    "  ntr = int(np.round(N * 0.8))\n",
    "  nval = int(np.round(N * 0.1))\n",
    "  ntest = N - ntr - nval\n",
    "\n",
    "  # spliting training, validation, and test\n",
    "\n",
    "  Xtrain = np.hstack([np.ones([ntr, 1]), white[ridx[0:ntr], 0:-1]])\n",
    "\n",
    "  ytrain = white[ridx[0:ntr], -1]\n",
    "\n",
    "  Xval = np.hstack([np.ones([nval, 1]), white[ridx[ntr:ntr + nval], 0:-1]])\n",
    "  yval = white[ridx[ntr:ntr + nval], -1]\n",
    "\n",
    "  Xtest = np.hstack([np.ones([ntest, 1]), white[ridx[ntr + nval:], 0:-1]])\n",
    "  ytest = white[ridx[ntr + nval:], -1]\n",
    "  return Xtrain, ytrain, Xval, yval, Xtest, ytest\n",
    "\n",
    "\n",
    "def main():\n",
    "  np.set_printoptions(precision=3)\n",
    "  Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing()\n",
    "  # =========================Q3.1 linear_regression=================================\n",
    "  w = linear_regression_noreg(Xtrain, ytrain)\n",
    "  print(\"======== Question 3.1 Linear Regression ========\")\n",
    "  print(\"dimensionality of the model parameter is \", len(w), \".\", sep=\"\")\n",
    "  print(\"model parameter is \", np.array_str(w))\n",
    "  \n",
    "  # =========================Q3.2 regularized linear_regression=====================\n",
    "  lambd = 5.0\n",
    "  wl = regularized_linear_regression(Xtrain, ytrain, lambd)\n",
    "  print(\"\\n\")\n",
    "  print(\"======== Question 3.2 Regularized Linear Regression ========\")\n",
    "  print(\"dimensionality of the model parameter is \", len(wl), sep=\"\")\n",
    "  print(\"lambda = \", lambd, \", model parameter is \", np.array_str(wl), sep=\"\")\n",
    "\n",
    "  # =========================Q3.3 tuning lambda======================\n",
    "  lambds = [0, 10 ** -4, 10 ** -3, 10 ** -2, 10 ** -1, 1, 10, 10 ** 2]\n",
    "  bestlambd = tune_lambda(Xtrain, ytrain, Xval, yval, lambds)\n",
    "  print(\"\\n\")\n",
    "  print(\"======== Question 3.3 tuning lambdas ========\")\n",
    "  print(\"tuning lambda, the best lambda =  \", bestlambd, sep=\"\")\n",
    "\n",
    "  # =========================Q3.4 report mse on test ======================\n",
    "  wbest = regularized_linear_regression(Xtrain, ytrain, bestlambd)\n",
    "  mse = test_error(wbest, Xtest, ytest)\n",
    "  print(\"\\n\")\n",
    "  print(\"======== Question 3.4 report MSE ========\")\n",
    "  print(\"MSE on test is %.3f\" % mse)\n",
    "  \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_processing():\n",
    "  white = pd.read_csv('winequality-white.csv', low_memory=False, sep=';').values\n",
    "\n",
    "  [N, d] = white.shape\n",
    "\n",
    "  np.random.seed(3)\n",
    "  # prepare data\n",
    "  ridx = np.random.permutation(N)\n",
    "  ntr = int(np.round(N * 0.8))\n",
    "  nval = int(np.round(N * 0.1))\n",
    "  ntest = N - ntr - nval\n",
    "\n",
    "  # spliting training, validation, and test\n",
    "\n",
    "  Xtrain = np.hstack([np.ones([ntr, 1]), white[ridx[0:ntr], 0:-1]])\n",
    "\n",
    "  ytrain = white[ridx[0:ntr], -1]\n",
    "\n",
    "  Xval = np.hstack([np.ones([nval, 1]), white[ridx[ntr:ntr + nval], 0:-1]])\n",
    "  yval = white[ridx[ntr:ntr + nval], -1]\n",
    "\n",
    "  Xtest = np.hstack([np.ones([ntest, 1]), white[ridx[ntr + nval:], 0:-1]])\n",
    "  ytest = white[ridx[ntr + nval:], -1]\n",
    "  return Xtrain, ytrain, Xval, yval, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3918, 12)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Q4.1 ######\n",
    "def linear_regression_noreg(X, y):\n",
    "    \"\"\"\n",
    "  Compute the weight parameter given X and y.\n",
    "  Inputs:\n",
    "  - X: A numpy array of shape (num_samples, D) containing feature.\n",
    "  - y: A numpy array of shape (num_samples, ) containing label\n",
    "  Returns:\n",
    "  - w: a numpy array of shape (D, )\n",
    "  \"\"\"\n",
    "  #####################################################\n",
    "  #\t\t\t\t YOUR CODE HERE\t\t\t\t\t                    #\n",
    "    Xmtx=np.asmatrix(X)\n",
    "    ymtx=np.asmatrix(y)\n",
    "    XmtxT=Xmtx.T\n",
    "    ymtxT=ymtx.T\n",
    "    w=np.asarray(np.linalg.pinv(XmtxT*Xmtx)*XmtxT*ymtxT)\n",
    "    w=w.ravel()\n",
    "  #####################################################\t\t \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Question 3.1 Linear Regression ========\n",
      "dimensionality of the model parameter is 12.\n",
      "model parameter is  [  2.166e+02   1.145e-01  -1.824e+00  -1.065e-02   1.037e-01   1.546e-01\n",
      "   3.416e-03   2.347e-04  -2.173e+02   8.348e-01   7.366e-01   1.153e-01]\n"
     ]
    }
   ],
   "source": [
    "  # =========================Q3.1 linear_regression=================================\n",
    "  w = linear_regression_noreg(Xtrain, ytrain)\n",
    "  print(\"======== Question 3.1 Linear Regression ========\")\n",
    "  print(\"dimensionality of the model parameter is \", len(w), \".\", sep=\"\")\n",
    "  print(\"model parameter is \", np.array_str(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Q4.2 ######\n",
    "def regularized_linear_regression(X, y, lambd):\n",
    "    \"\"\"\n",
    "    Compute the weight parameter given X, y and lambda.\n",
    "    Inputs:\n",
    "    - X: A numpy array of shape (num_samples, D) containing feature.\n",
    "    - y: A numpy array of shape (num_samples, ) containing label\n",
    "    - lambd: a float number containing regularization strength\n",
    "    Returns:\n",
    "    - w: a numpy array of shape (D, )\n",
    "    \"\"\"\n",
    "  #####################################################\n",
    "  #\t\t\t\t YOUR CODE HERE\t\t\t\t\t    #\n",
    "    Xmtx=np.asmatrix(X)\n",
    "    ymtx=np.asmatrix(y)\n",
    "    XmtxT=Xmtx.T\n",
    "    ymtxT=ymtx.T\n",
    "    I=np.identity(X.shape[1])\n",
    "    w=np.asarray(np.linalg.pinv(XmtxT*Xmtx+lambd*I)*XmtxT*ymtxT)\n",
    "    w=w.ravel()\n",
    "  #####################################################\t\t \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======== Question 3.2 Regularized Linear Regression ========\n",
      "dimensionality of the model parameter is 12\n",
      "lambda = 5.0, model parameter is [  6.324e-01  -2.854e-02  -1.641e+00  -3.577e-02   2.803e-02  -1.362e-01\n",
      "   5.259e-03  -8.421e-04   5.888e-01   2.887e-01   4.162e-01   3.768e-01]\n"
     ]
    }
   ],
   "source": [
    "  # =========================Q3.2 regularized linear_regression=====================\n",
    "lambd = 5.0\n",
    "wl = regularized_linear_regression(Xtrain, ytrain, lambd)\n",
    "print(\"\\n\")\n",
    "print(\"======== Question 3.2 Regularized Linear Regression ========\")\n",
    "print(\"dimensionality of the model parameter is \", len(wl), sep=\"\")\n",
    "print(\"lambda = \", lambd, \", model parameter is \", np.array_str(wl), sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Q4.3 ###### \n",
    "def tune_lambda(Xtrain, ytrain, Xval, yval, lambds):\n",
    "    \"\"\"\n",
    "    Find the best lambda value.\n",
    "    Inputs:\n",
    "    - Xtrain: A numpy array of shape (num_training_samples, D) containing training feature.\n",
    "    - ytrain: A numpy array of shape (num_training_samples, ) containing training label\n",
    "    - Xval: A numpy array of shape (num_val_samples, D) containing validation feature.\n",
    "    - yval: A numpy array of shape (num_val_samples, ) containing validation label\n",
    "    - lambds: a list of lambdas\n",
    "    Returns:\n",
    "    - bestlambda: the best lambda you find in lambds\n",
    "    \"\"\"\n",
    "  #####################################################\n",
    "  #\t\t\t\t YOUR CODE HERE\t\t\t\t\t                    #\n",
    "    valerr=[]\n",
    "    Xmtx=np.asmatrix(Xtrain)\n",
    "    ymtx=np.asmatrix(ytrain)\n",
    "    Xvmtx=np.asmatrix(Xval)\n",
    "    yvmtx=np.asmatrix(yval)\n",
    "    XmtxT=Xmtx.T\n",
    "    ymtxT=ymtx.T\n",
    "    yvmtxT=yvmtx.T\n",
    "    I=np.identity(Xtrain.shape[1])\n",
    "    for lambd in lambds:\n",
    "        w_lambd=np.linalg.pinv(XmtxT*Xmtx+lambd*I)*XmtxT*ymtxT  # D*1\n",
    "        y_pred=Xval*w_lambd  #N*1\n",
    "        err=np.average(np.square(np.asarray(yvmtx.T-Xvmtx*w_lambd)))\n",
    "        valerr.append(err)\n",
    "    bestlambd=lambds[valerr.index(min(valerr))]\n",
    "        \n",
    "  #####################################################\t\t \n",
    "    return bestlambd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======== Question 3.3 tuning lambdas ========\n",
      "tuning lambda, the best lambda =  0.001\n"
     ]
    }
   ],
   "source": [
    "# =========================Q3.3 tuning lambda======================\n",
    "lambds = [0, 10 ** -4, 10 ** -3, 10 ** -2, 10 ** -1, 1, 10, 10 ** 2]\n",
    "bestlambd = tune_lambda(Xtrain, ytrain, Xval, yval, lambds)\n",
    "print(\"\\n\")\n",
    "print(\"======== Question 3.3 tuning lambdas ========\")\n",
    "print(\"tuning lambda, the best lambda =  \", bestlambd, sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### Q4.4 ######\n",
    "def test_error(w, X, y):\n",
    "    \"\"\"\n",
    "    Compute the mean squre error on test set given X, y, and model parameter w.\n",
    "    Inputs:\n",
    "    - X: A numpy array of shape (num_samples, D) containing test feature.\n",
    "    - y: A numpy array of shape (num_samples, ) containing test label\n",
    "    - w: a numpy array of shape (D, )\n",
    "    Returns:\n",
    "    - err: the mean square error\n",
    "    \"\"\"\n",
    "    Xmtx=np.asmatrix(X)      #490*12\n",
    "    ymtx=np.asmatrix(y)      #1*490\n",
    "    wmtx=np.asmatrix(w)      #1*12\n",
    "    wmtxT=wmtx.T             #12*1\n",
    "    XmtxT=Xmtx.T             #490*12\n",
    "    ymtxT=ymtx.T             #490*1\n",
    "    err=np.average(np.square(np.asarray(ymtxT-Xmtx*wmtxT)))\n",
    "    return err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======== Question 3.4 report MSE ========\n",
      "MSE on test is 0.512\n"
     ]
    }
   ],
   "source": [
    "# =========================Q3.4 report mse on test ======================\n",
    "wbest = regularized_linear_regression(Xtrain, ytrain, bestlambd)\n",
    "mse = test_error(wbest, Xtest, ytest)\n",
    "print(\"\\n\")\n",
    "print(\"======== Question 3.4 report MSE ========\")\n",
    "print(\"MSE on test is %.3f\" % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 12)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note:\n",
    "Xtest.shape\n",
    "np.asmatrix(Xtest).shape\n",
    "ytest.shape     # array: (490,)\n",
    "np.asmatrix(ytest).shape   # matrix: (1,490) reverse!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Question 3.1 Linear Regression ========\n",
      "dimensionality of the model parameter is 12.\n",
      "model parameter is  [  2.166e+02   1.145e-01  -1.824e+00  -1.065e-02   1.037e-01   1.546e-01\n",
      "   3.416e-03   2.347e-04  -2.173e+02   8.348e-01   7.366e-01   1.153e-01]\n",
      "\n",
      "\n",
      "======== Question 3.2 Regularized Linear Regression ========\n",
      "dimensionality of the model parameter is 12\n",
      "lambda = 5.0, model parameter is [  6.324e-01  -2.854e-02  -1.641e+00  -3.577e-02   2.803e-02  -1.362e-01\n",
      "   5.259e-03  -8.421e-04   5.888e-01   2.887e-01   4.162e-01   3.768e-01]\n",
      "\n",
      "\n",
      "======== Question 3.3 tuning lambdas ========\n",
      "tuning lambda, the best lambda =  0.001\n",
      "\n",
      "\n",
      "======== Question 3.4 report MSE ========\n",
      "MSE on test is 0.512\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Do not change the input and output format.\n",
    "If our script cannot run your code or the format is improper, your code will not be graded.\n",
    "\n",
    "The only functions you need to implement in this template is linear_regression_noreg, regularized_linear_regression,\n",
    "tune_lambda, and test_error.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "###### Q4.1 ######\n",
    "def linear_regression_noreg(X, y):\n",
    "  \"\"\"\n",
    "  Compute the weight parameter given X and y.\n",
    "  Inputs:\n",
    "  - X: A numpy array of shape (num_samples, D) containing feature.\n",
    "  - y: A numpy array of shape (num_samples, ) containing label\n",
    "  Returns:\n",
    "  - w: a numpy array of shape (D, )\n",
    "  \"\"\"\n",
    "  #####################################################\n",
    "  #\t\t\t\t YOUR CODE HERE\t\t\t\t\t                    #\n",
    "  Xmtx=np.asmatrix(X)\n",
    "  ymtx=np.asmatrix(y)\n",
    "  XmtxT=Xmtx.T\n",
    "  ymtxT=ymtx.T\n",
    "  w=np.asarray(np.linalg.pinv(XmtxT*Xmtx)*XmtxT*ymtxT)\n",
    "  w=w.ravel()\n",
    "  #####################################################\t\t \n",
    "  return w\n",
    "\n",
    "###### Q4.2 ######\n",
    "def regularized_linear_regression(X, y, lambd):\n",
    "  \"\"\"\n",
    "    Compute the weight parameter given X, y and lambda.\n",
    "    Inputs:\n",
    "    - X: A numpy array of shape (num_samples, D) containing feature.\n",
    "    - y: A numpy array of shape (num_samples, ) containing label\n",
    "    - lambd: a float number containing regularization strength\n",
    "    Returns:\n",
    "    - w: a numpy array of shape (D, )\n",
    "    \"\"\"\n",
    "  #####################################################\n",
    "  #\t\t\t\t YOUR CODE HERE\t\t\t\t\t                    #\n",
    "  Xmtx=np.asmatrix(X)\n",
    "  ymtx=np.asmatrix(y)\n",
    "  XmtxT=Xmtx.T\n",
    "  ymtxT=ymtx.T\n",
    "  I=np.identity(X.shape[1])\n",
    "  w=np.asarray(np.linalg.pinv(XmtxT*Xmtx+lambd*I)*XmtxT*ymtxT)\n",
    "  w=w.ravel()\n",
    "  #####################################################\t\t \n",
    "  return w\n",
    "\n",
    "###### Q4.3 ######\n",
    "def tune_lambda(Xtrain, ytrain, Xval, yval, lambds):\n",
    "  \"\"\"\n",
    "    Find the best lambda value.\n",
    "    Inputs:\n",
    "    - Xtrain: A numpy array of shape (num_training_samples, D) containing training feature.\n",
    "    - ytrain: A numpy array of shape (num_training_samples, ) containing training label\n",
    "    - Xval: A numpy array of shape (num_val_samples, D) containing validation feature.\n",
    "    - yval: A numpy array of shape (num_val_samples, ) containing validation label\n",
    "    - lambds: a list of lambdas\n",
    "    Returns:\n",
    "    - bestlambda: the best lambda you find in lambds\n",
    "    \"\"\"\n",
    "  #####################################################\n",
    "  #\t\t\t\t YOUR CODE HERE\t\t\t\t\t                    #\n",
    "  valerr=[]\n",
    "  Xmtx=np.asmatrix(Xtrain)\n",
    "  ymtx=np.asmatrix(ytrain)\n",
    "  Xvmtx=np.asmatrix(Xval)\n",
    "  yvmtx=np.asmatrix(yval)\n",
    "  XmtxT=Xmtx.T\n",
    "  ymtxT=ymtx.T\n",
    "  yvmtxT=yvmtx.T\n",
    "  I=np.identity(Xtrain.shape[1])\n",
    "  for lambd in lambds:\n",
    "    w_lambd=np.linalg.pinv(XmtxT*Xmtx+lambd*I)*XmtxT*ymtxT  # D*1\n",
    "    y_pred=Xval*w_lambd  #N*1\n",
    "    err=np.average(np.square(np.asarray(yvmtx.T-Xvmtx*w_lambd)))\n",
    "    valerr.append(err)\n",
    "  bestlambda=lambds[valerr.index(min(valerr))]\n",
    "  #####################################################\t\t \n",
    "  return bestlambda\n",
    "\n",
    "###### Q4.4 ######\n",
    "def test_error(w, X, y):\n",
    "  \"\"\"\n",
    "    Compute the mean squre error on test set given X, y, and model parameter w.\n",
    "    Inputs:\n",
    "    - X: A numpy array of shape (num_samples, D) containing test feature.\n",
    "    - y: A numpy array of shape (num_samples, ) containing test label\n",
    "    - w: a numpy array of shape (D, )\n",
    "    Returns:\n",
    "    - err: the mean square error\n",
    "    \"\"\"\n",
    "  Xmtx=np.asmatrix(X)      #490*12\n",
    "  ymtx=np.asmatrix(y)      #1*490\n",
    "  wmtx=np.asmatrix(w)      #1*12\n",
    "  wmtxT=wmtx.T             #12*1\n",
    "  XmtxT=Xmtx.T             #490*12\n",
    "  ymtxT=ymtx.T             #490*1\n",
    "  err=np.average(np.square(np.asarray(ymtxT-Xmtx*wmtxT)))\n",
    "  return err\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "NO MODIFICATIONS below this line.\n",
    "You should only write your code in the above functions.\n",
    "\"\"\"\n",
    "\n",
    "def data_processing():\n",
    "  white = pd.read_csv('winequality-white.csv', low_memory=False, sep=';').values\n",
    "\n",
    "  [N, d] = white.shape\n",
    "\n",
    "  np.random.seed(3)\n",
    "  # prepare data\n",
    "  ridx = np.random.permutation(N)\n",
    "  ntr = int(np.round(N * 0.8))\n",
    "  nval = int(np.round(N * 0.1))\n",
    "  ntest = N - ntr - nval\n",
    "\n",
    "  # spliting training, validation, and test\n",
    "\n",
    "  Xtrain = np.hstack([np.ones([ntr, 1]), white[ridx[0:ntr], 0:-1]])\n",
    "\n",
    "  ytrain = white[ridx[0:ntr], -1]\n",
    "\n",
    "  Xval = np.hstack([np.ones([nval, 1]), white[ridx[ntr:ntr + nval], 0:-1]])\n",
    "  yval = white[ridx[ntr:ntr + nval], -1]\n",
    "\n",
    "  Xtest = np.hstack([np.ones([ntest, 1]), white[ridx[ntr + nval:], 0:-1]])\n",
    "  ytest = white[ridx[ntr + nval:], -1]\n",
    "  return Xtrain, ytrain, Xval, yval, Xtest, ytest\n",
    "\n",
    "\n",
    "def main():\n",
    "  np.set_printoptions(precision=3)\n",
    "  Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing()\n",
    "  # =========================Q3.1 linear_regression=================================\n",
    "  w = linear_regression_noreg(Xtrain, ytrain)\n",
    "  print(\"======== Question 3.1 Linear Regression ========\")\n",
    "  print(\"dimensionality of the model parameter is \", len(w), \".\", sep=\"\")\n",
    "  print(\"model parameter is \", np.array_str(w))\n",
    "  \n",
    "  # =========================Q3.2 regularized linear_regression=====================\n",
    "  lambd = 5.0\n",
    "  wl = regularized_linear_regression(Xtrain, ytrain, lambd)\n",
    "  print(\"\\n\")\n",
    "  print(\"======== Question 3.2 Regularized Linear Regression ========\")\n",
    "  print(\"dimensionality of the model parameter is \", len(wl), sep=\"\")\n",
    "  print(\"lambda = \", lambd, \", model parameter is \", np.array_str(wl), sep=\"\")\n",
    "\n",
    "  # =========================Q3.3 tuning lambda======================\n",
    "  lambds = [0, 10 ** -4, 10 ** -3, 10 ** -2, 10 ** -1, 1, 10, 10 ** 2]\n",
    "  bestlambd = tune_lambda(Xtrain, ytrain, Xval, yval, lambds)\n",
    "  print(\"\\n\")\n",
    "  print(\"======== Question 3.3 tuning lambdas ========\")\n",
    "  print(\"tuning lambda, the best lambda =  \", bestlambd, sep=\"\")\n",
    "\n",
    "  # =========================Q3.4 report mse on test ======================\n",
    "  wbest = regularized_linear_regression(Xtrain, ytrain, bestlambd)\n",
    "  mse = test_error(wbest, Xtest, ytest)\n",
    "  print(\"\\n\")\n",
    "  print(\"======== Question 3.4 report MSE ========\")\n",
    "  print(\"MSE on test is %.3f\" % mse)\n",
    "  \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
